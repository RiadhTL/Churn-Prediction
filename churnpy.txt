1-la nature du probleme est supervise car on une variable cible connue Exited ,le type de sortie est classification car on cherche a predire une classe et non une valreur continue 

*****

2- la variable age semble la plus pertinente avec 0.29 corr avec exited et on peut ajouter la colonne isactivenumber avec -0.16.

3-Aucune valeur manquante dans le dataset.

Pr√©sence de valeurs extr√™mes, notamment pour Age, Balance, NumOfProducts, mais elles sont plausibles et proviennent de comportements r√©els, donc on ne les supprime pas.

Pour √©viter leur impact n√©gatif sur certains mod√®les, on utilisera une normalisation robuste (RobustScaler).

Les variables non informatives (CustomerId, RowNumber) seront supprim√©es.

2***********************************
1-- la variable age semble la plus pertinente avec 0.29 corr avec exited et on peut ajouter la colonne isactivenumber avec -0.16.


2--Les variables Geography et Gender n√©cessitent un encodage car elles sont cat√©gorielles, tandis que Balance
 et EstimatedSalary doivent √™tre normalis√©es en raison de leurs √©chelles tr√®s √©lev√©es et de leur dispersion importante.


3-Les distributions avec hue=Exited sont les visualisations les plus informatives, car elles permettent d‚Äôobserver pr√©cis√©ment les diff√©rences de densit√© entre les clients quittant la banque et ceux qui restent, ce qui r√©v√®le le vrai pouvoir explicatif des variables.


3***************************************
1-
-- gender est encod√© en binaire car il s‚Äôagit d‚Äôune variable √† deux modalit√©s, tandis que Geography est encod√© en one-hot car il s‚Äôagit d‚Äôune variable nominale sans ordre naturel.

-- Geography is a nominal categorical variable without order, so One-Hot Encoding is the correct method. Label Encoding would force an artificial order (0, 1, 2), causing the model to treat ‚ÄúFrance < Spain < Germany‚Äù, which is meaningless. One-Hot Encoding allows each country to be represented independently.


2- J‚Äôai choisi la standardisation (StandardScaler) car les variables num√©riques n‚Äôont pas la m√™me √©chelle et plusieurs mod√®les envisag√©s (logistic regression, SVM, r√©seaux neuronaux) sont sensibles √† la variance des features. StandardScaler est adapt√© √† des donn√©es mod√©r√©ment distribu√©es et moins sensible aux outliers que MinMax.
 

3-- il est  indispensable de s√©parer les donn√©es avant l‚Äôentra√Ænement  pour √âvaluer le mod√®le sur des donn√©es jamais vues, eviter le surapprentissage et la fuite de donnes .

4----------------
1- La r√©gression logistique a √©t√© choisie pour sa simplicit√©, sa rapidit√© et son interpr√©tabilit√©, ce qui en fait un excellent mod√®le de r√©f√©rence pour pr√©dire le churn.
 Le Random Forest a √©t√© choisi pour sa capacit√© √† capturer des relations complexes et non lin√©aires entre les variables, et pour ses bonnes performances sur les donn√©es tabulaires.

2-J‚Äôai ajust√© le param√®tre C pour contr√¥ler la r√©gularisation et √©viter le surapprentissage, ainsi que le solver afin d‚Äôoptimiser la convergence pour ce dataset.

üëâ Random Forest :
J‚Äôai ajust√© n_estimators pour am√©liorer la stabilit√©, max_depth et min_samples_split pour contr√¥ler la complexit√© des arbres, et max_features pour augmenter la diversit√© et r√©duire la variance.

3- pour la reg linear le temps d execution est 0.1 s et pour le random forrest a un temps d execution de 1.14 minutes

5***********************************************************

1--Non, l‚Äôaccuracy n‚Äôest pas suffisante car le dataset pr√©sente un d√©s√©quilibre important entre les clients qui quittent la banque et ceux qui restent.

2-- Le Random Forest est le mod√®le le plus performant. Il obtient le meilleur score AUC-ROC (0.858), un F1-score sup√©rieur sur la classe churn (0.63), et une meilleure accuracy globale. Il produit √©galement une matrice de confusion plus √©quilibr√©e, avec moins d‚Äôerreurs critiques et un meilleur compromis pr√©cision/rappel. Ces r√©sultats montrent que le Random Forest distingue plus efficacement les churners des non-churners que la r√©gression logistique.

3--Le mod√®le commet davantage d‚Äôerreurs sur les clients restant (187 faux positifs) que sur les clients qui quittent (135 faux n√©gatifs). D‚Äôun point de vue business, cela implique un co√ªt marketing inutile, car certaines actions de r√©tention seront d√©clench√©es pour des clients qui n‚Äôauraient pas churn√©. Cependant, les faux n√©gatifs restent l‚Äôerreur la plus dommageable, car ils repr√©sentent des clients r√©ellement perdus. Le mod√®le actuel r√©ussit donc √† limiter les pertes directes, au prix d‚Äôun effort marketing plus important.

6--------------------------------------------------

1-





































